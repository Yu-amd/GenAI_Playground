model_id: amd/Llama-3_1-405B-Instruct-FP8-KV
name: Llama 3.1 405B Instruct FP8 KV
builder: AMD
family: Llama
size: 405B
huggingface_id: amd/Llama-3_1-405B-Instruct-FP8-KV
description: 'AMD''s Llama-3.1-405B-Instruct-FP8-KV is a quantized version of Meta''s
  Llama 3.1 405B Instruct model  using AMD''s Quark framework. It applies FP8 quantization
  to weights, activations, and KV cache,  significantly reducing memory usage while
  maintaining high accuracy. The model uses symmetric per-tensor  quantization for
  optimal performance on AMD hardware.

  '
logo: model_llama3_1_405b_fp8.png
readiness_level: Production-Ready
status_badges:
- FP8
- FlashAttention
- Featured
tags:
- Text Generation
- Multilingual
- Instruction-Tuned
- vLLM-Compatible
- Efficient
license: Meta RAIL
endpoint: https://api.inference-hub.com/v1/chat/completions
demo_assets:
  notebook: https://github.com/inference-hub/notebooks/llama-3-1-405b-fp8-kv-demo.ipynb
  demo_link: https://playground.inference-hub.com/models/amd/Llama-3.1-405B-Instruct-FP8-KV
aim_recipes:
- name: MI300X FP8
  hardware: MI300X
  precision: fp8
  recipe_file: configs/llama-3-1-405b-fp8-kv-mi300x-fp8.yaml
- name: MI250 FP8
  hardware: MI250
  precision: fp8
  recipe_file: configs/llama-3-1-405b-fp8-kv-mi250-fp8.yaml
api_examples:
  python: "import requests\n\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\"\
    ,\n    \"Content-Type\": \"application/json\"\n}\n\npayload = {\n    \"model\"\
    : \"amd/Llama-3.1-405B-Instruct-FP8-KV\",\n    \"messages\": [{\"role\": \"user\"\
    , \"content\": \"Hello\"}],\n    \"stream\": False\n}\n\nresponse = requests.post(\"\
    https://api.inference-hub.com/v1/chat/completions\", headers=headers, json=payload)\n\
    print(response.json())\n"
  javascript: "const response = await fetch(\"https://api.inference-hub.com/v1/chat/completions\"\
    , {\n  method: \"POST\",\n  headers: {\n    \"Authorization\": \"Bearer YOUR_API_KEY\"\
    ,\n    \"Content-Type\": \"application/json\"\n  },\n  body: JSON.stringify({\n\
    \    model: \"amd/Llama-3.1-405B-Instruct-FP8-KV\",\n    messages: [{ role: \"\
    user\", content: \"Hello\" }],\n    stream: false\n  })\n});\n\nconst data = await\
    \ response.json();\nconsole.log(data.choices[0].message.content);\n"
  shell: "curl -X POST https://api.inference-hub.com/v1/chat/completions \\\n  -H\
    \ \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
    \ \\\n  -d '{\n    \"model\": \"amd/Llama-3.1-405B-Instruct-FP8-KV\",\n    \"\
    messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n    \"stream\": false\n\
    \  }'\n"
  java: "HttpClient client = HttpClient.newHttpClient();\nHttpRequest request = HttpRequest.newBuilder()\n\
    \    .uri(URI.create(\"https://api.inference-hub.com/v1/chat/completions\"))\n\
    \    .header(\"Authorization\", \"Bearer YOUR_API_KEY\")\n    .header(\"Content-Type\"\
    , \"application/json\")\n    .POST(HttpRequest.BodyPublishers.ofString(\"\"\"\n\
    \      {\n        \"model\": \"amd/Llama-3.1-405B-Instruct-FP8-KV\",\n       \
    \ \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n        \"stream\"\
    : false\n      }\n    \"\"\"))\n    .build();\n\nHttpResponse<String> response\
    \ = client.send(request, HttpResponse.BodyHandlers.ofString());\nSystem.out.println(response.body());\n"
  go: "package main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"io/ioutil\"\n \
    \   \"net/http\"\n)\n\nfunc main() {\n    jsonStr := []byte(`{\n        \"model\"\
    : \"amd/Llama-3.1-405B-Instruct-FP8-KV\",\n        \"messages\": [{\"role\": \"\
    user\", \"content\": \"Hello\"}],\n        \"stream\": false\n    }`)\n\n    req,\
    \ _ := http.NewRequest(\"POST\", \"https://api.inference-hub.com/v1/chat/completions\"\
    , bytes.NewBuffer(jsonStr))\n    req.Header.Set(\"Authorization\", \"Bearer YOUR_API_KEY\"\
    )\n    req.Header.Set(\"Content-Type\", \"application/json\")\n\n    client :=\
    \ &http.Client{}\n    resp, _ := client.Do(req)\n    body, _ := ioutil.ReadAll(resp.Body)\n\
    \    fmt.Println(string(body))\n}\n"
  csharp: "using System.Net.Http;\nusing System.Text;\nusing System.Threading.Tasks;\n\
    \nvar client = new HttpClient();\nvar request = new HttpRequestMessage(HttpMethod.Post,\
    \ \"https://api.inference-hub.com/v1/chat/completions\");\nrequest.Headers.Add(\"\
    Authorization\", \"Bearer YOUR_API_KEY\");\n\nvar json = \"\"\"\n{\n    \"model\"\
    : \"amd/Llama-3.1-405B-Instruct-FP8-KV\",\n    \"messages\": [{\"role\": \"user\"\
    , \"content\": \"Hello\"}],\n    \"stream\": false\n}\n\"\"\";\n\nrequest.Content\
    \ = new StringContent(json, Encoding.UTF8, \"application/json\");\n\nvar response\
    \ = await client.SendAsync(request);\nvar responseBody = await response.Content.ReadAsStringAsync();\n\
    Console.WriteLine(responseBody);\n"
model_card:
  overview: ''
  intended_use: []
  limitations: []
  training_data: ''
  evaluation: []
  known_issues: []
  references: []
