model_id: deepseek-ai/deepseek-moe-16b-base
name: DeepSeek MoE 16B Base
builder: DeepSeek AI
family: DeepSeek MoE
size: 16.4B
huggingface_id: deepseek-ai/deepseek-moe-16b-base
description: 'Mixture-of-Experts (MoE) language model with 16.4B parameters. It employs
  an innovative MoE architecture, which involves two principal strategies: fine-grained
  expert segmentation and shared experts isolation. This base model provides excellent
  efficiency and performance for various language tasks.

  '
logo: model_DeepSeek_MoE_18B.png
readiness_level: Day-0 Available
status_badges:
- FP16
- FlashAttention
- New
tags:
- MoE Architecture
- Efficient
- Base Model
- vLLM-Compatible
- Lightweight
license: Apache 2.0
endpoint: https://api.inference-hub.com/v1/chat/completions
demo_assets:
  notebook: https://github.com/inference-hub/notebooks/deepseek-moe-16b-base-demo.ipynb
  demo_link: https://playground.inference-hub.com/models/deepseek-ai/deepseek-moe-16b-base
aim_recipes:
- name: MI300X FP16
  hardware: MI300X
  precision: fp16
  recipe_file: configs/deepseek-moe-16b-base-mi300x-fp16.yaml
- name: MI250 FP16
  hardware: MI250
  precision: fp16
  recipe_file: configs/deepseek-moe-16b-base-mi250-fp16.yaml
api_examples:
  python: "import requests\n\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\"\
    ,\n    \"Content-Type\": \"application/json\"\n}\n\npayload = {\n    \"model\"\
    : \"deepseek-ai/deepseek-moe-16b-base\",\n    \"messages\": [{\"role\": \"user\"\
    , \"content\": \"Hello\"}],\n    \"stream\": False\n}\n\nresponse = requests.post(\"\
    https://api.inference-hub.com/v1/chat/completions\", headers=headers, json=payload)\n\
    print(response.json())\n"
  javascript: "const response = await fetch(\"https://api.inference-hub.com/v1/chat/completions\"\
    , {\n  method: \"POST\",\n  headers: {\n    \"Authorization\": \"Bearer YOUR_API_KEY\"\
    ,\n    \"Content-Type\": \"application/json\"\n  },\n  body: JSON.stringify({\n\
    \    model: \"deepseek-ai/deepseek-moe-16b-base\",\n    messages: [{ role: \"\
    user\", content: \"Hello\" }],\n    stream: false\n  })\n});\n\nconst data = await\
    \ response.json();\nconsole.log(data.choices[0].message.content);\n"
  shell: "curl -X POST https://api.inference-hub.com/v1/chat/completions \\\n  -H\
    \ \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
    \ \\\n  -d '{\n    \"model\": \"deepseek-ai/deepseek-moe-16b-base\",\n    \"messages\"\
    : [{\"role\": \"user\", \"content\": \"Hello\"}],\n    \"stream\": false\n  }'\n"
  java: "HttpClient client = HttpClient.newHttpClient();\nHttpRequest request = HttpRequest.newBuilder()\n\
    \    .uri(URI.create(\"https://api.inference-hub.com/v1/chat/completions\"))\n\
    \    .header(\"Authorization\", \"Bearer YOUR_API_KEY\")\n    .header(\"Content-Type\"\
    , \"application/json\")\n    .POST(HttpRequest.BodyPublishers.ofString(\"\"\"\n\
    \      {\n        \"model\": \"deepseek-ai/deepseek-moe-16b-base\",\n        \"\
    messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n        \"stream\"\
    : false\n      }\n    \"\"\"))\n    .build();\n\nHttpResponse<String> response\
    \ = client.send(request, HttpResponse.BodyHandlers.ofString());\nSystem.out.println(response.body());\n"
  go: "package main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"io/ioutil\"\n \
    \   \"net/http\"\n)\n\nfunc main() {\n    jsonStr := []byte(`{\n        \"model\"\
    : \"deepseek-ai/deepseek-moe-16b-base\",\n        \"messages\": [{\"role\": \"\
    user\", \"content\": \"Hello\"}],\n        \"stream\": false\n    }`)\n\n    req,\
    \ _ := http.NewRequest(\"POST\", \"https://api.inference-hub.com/v1/chat/completions\"\
    , bytes.NewBuffer(jsonStr))\n    req.Header.Set(\"Authorization\", \"Bearer YOUR_API_KEY\"\
    )\n    req.Header.Set(\"Content-Type\", \"application/json\")\n\n    client :=\
    \ &http.Client{}\n    resp, _ := client.Do(req)\n    body, _ := ioutil.ReadAll(resp.Body)\n\
    \    fmt.Println(string(body))\n}\n"
  csharp: "using System.Net.Http;\nusing System.Text;\nusing System.Threading.Tasks;\n\
    \nvar client = new HttpClient();\nvar request = new HttpRequestMessage(HttpMethod.Post,\
    \ \"https://api.inference-hub.com/v1/chat/completions\");\nrequest.Headers.Add(\"\
    Authorization\", \"Bearer YOUR_API_KEY\");\n\nvar json = \"\"\"\n{\n    \"model\"\
    : \"deepseek-ai/deepseek-moe-16b-base\",\n    \"messages\": [{\"role\": \"user\"\
    , \"content\": \"Hello\"}],\n    \"stream\": false\n}\n\"\"\";\n\nrequest.Content\
    \ = new StringContent(json, Encoding.UTF8, \"application/json\");\n\nvar response\
    \ = await client.SendAsync(request);\nvar responseBody = await response.Content.ReadAsStringAsync();\n\
    Console.WriteLine(responseBody);\n"
model_card:
  overview: 'license_name: deepseek license_link: https://github.com/deepseek-ai/DeepSeek-MoE/blob/main/LICENSE-MODEL
    <img width="500px" alt="DeepSeek Chat" src="https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/images/logo.png?raw=true">'
  intended_use:
  - Text-Generation tasks
  limitations:
  - May generate biased or harmful content
  - Not suitable for safety-critical applications
  - Performance may vary across different tasks and domains
  training_data: Training data information not specified in model card.
  evaluation:
  - Evaluation metrics not specified in model card
  known_issues:
  - May produce biased content
  - Limited reasoning capabilities
  - Performance varies across languages and domains
  references:
  - https://huggingface.co/deepseek-ai/deepseek-moe-16b-base
