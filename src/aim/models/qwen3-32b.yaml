model_id: Qwen/Qwen3-32B
name: Qwen3 32B
builder: Alibaba Qwen Team
family: Qwen3
size: 32.8B
huggingface_id: Qwen/Qwen3-32B
description: 'Qwen3-32B is the latest generation of large language models in the Qwen
  series, offering groundbreaking  advancements in reasoning, instruction-following,
  agent capabilities, and multilingual support.  It uniquely supports seamless switching
  between thinking mode (for complex logical reasoning, math, and coding)  and non-thinking
  mode (for efficient, general-purpose dialogue) within a single model.

  '
logo: model_qwen3_32b.png
readiness_level: Production-Ready
status_badges:
- BF16
- FlashAttention
- Featured
tags:
- Text Generation
- Reasoning
- Code Generation
- Multilingual
- Instruction-Tuned
- vLLM-Compatible
- sglang-Compatible
license: Apache 2.0
endpoint: https://api.inference-hub.com/v1/chat/completions
demo_assets:
  notebook: https://github.com/inference-hub/notebooks/qwen3-32b-demo.ipynb
  demo_link: https://playground.inference-hub.com/models/Qwen/Qwen3-32B
aim_recipes:
- name: MI300X BF16
  hardware: MI300X
  precision: bf16
  recipe_file: configs/qwen3-32b-mi300x-bf16.yaml
- name: MI250 BF16
  hardware: MI250
  precision: bf16
  recipe_file: configs/qwen3-32b-mi250-bf16.yaml
api_examples:
  python: "import requests\n\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\"\
    ,\n    \"Content-Type\": \"application/json\"\n}\n\npayload = {\n    \"model\"\
    : \"Qwen/Qwen3-32B\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"\
    Hello\"}],\n    \"stream\": False\n}\n\nresponse = requests.post(\"https://api.inference-hub.com/v1/chat/completions\"\
    , headers=headers, json=payload)\nprint(response.json())\n"
  javascript: "const response = await fetch(\"https://api.inference-hub.com/v1/chat/completions\"\
    , {\n  method: \"POST\",\n  headers: {\n    \"Authorization\": \"Bearer YOUR_API_KEY\"\
    ,\n    \"Content-Type\": \"application/json\"\n  },\n  body: JSON.stringify({\n\
    \    model: \"Qwen/Qwen3-32B\",\n    messages: [{ role: \"user\", content: \"\
    Hello\" }],\n    stream: false\n  })\n});\n\nconst data = await response.json();\n\
    console.log(data.choices[0].message.content);\n"
  shell: "curl -X POST https://api.inference-hub.com/v1/chat/completions \\\n  -H\
    \ \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
    \ \\\n  -d '{\n    \"model\": \"Qwen/Qwen3-32B\",\n    \"messages\": [{\"role\"\
    : \"user\", \"content\": \"Hello\"}],\n    \"stream\": false\n  }'\n"
  java: "HttpClient client = HttpClient.newHttpClient();\nHttpRequest request = HttpRequest.newBuilder()\n\
    \    .uri(URI.create(\"https://api.inference-hub.com/v1/chat/completions\"))\n\
    \    .header(\"Authorization\", \"Bearer YOUR_API_KEY\")\n    .header(\"Content-Type\"\
    , \"application/json\")\n    .POST(HttpRequest.BodyPublishers.ofString(\"\"\"\n\
    \      {\n        \"model\": \"Qwen/Qwen3-32B\",\n        \"messages\": [{\"role\"\
    : \"user\", \"content\": \"Hello\"}],\n        \"stream\": false\n      }\n  \
    \  \"\"\"))\n    .build();\n\nHttpResponse<String> response = client.send(request,\
    \ HttpResponse.BodyHandlers.ofString());\nSystem.out.println(response.body());\n"
  go: "package main\n\nimport (\n    \"bytes\"\n    \"fmt\"\n    \"io/ioutil\"\n \
    \   \"net/http\"\n)\n\nfunc main() {\n    jsonStr := []byte(`{\n        \"model\"\
    : \"Qwen/Qwen3-32B\",\n        \"messages\": [{\"role\": \"user\", \"content\"\
    : \"Hello\"}],\n        \"stream\": false\n    }`)\n\n    req, _ := http.NewRequest(\"\
    POST\", \"https://api.inference-hub.com/v1/chat/completions\", bytes.NewBuffer(jsonStr))\n\
    \    req.Header.Set(\"Authorization\", \"Bearer YOUR_API_KEY\")\n    req.Header.Set(\"\
    Content-Type\", \"application/json\")\n\n    client := &http.Client{}\n    resp,\
    \ _ := client.Do(req)\n    body, _ := ioutil.ReadAll(resp.Body)\n    fmt.Println(string(body))\n\
    }\n"
  csharp: "using System.Net.Http;\nusing System.Text;\nusing System.Threading.Tasks;\n\
    \nvar client = new HttpClient();\nvar request = new HttpRequestMessage(HttpMethod.Post,\
    \ \"https://api.inference-hub.com/v1/chat/completions\");\nrequest.Headers.Add(\"\
    Authorization\", \"Bearer YOUR_API_KEY\");\n\nvar json = \"\"\"\n{\n    \"model\"\
    : \"Qwen/Qwen3-32B\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"\
    Hello\"}],\n    \"stream\": false\n}\n\"\"\";\n\nrequest.Content = new StringContent(json,\
    \ Encoding.UTF8, \"application/json\");\n\nvar response = await client.SendAsync(request);\n\
    var responseBody = await response.Content.ReadAsStringAsync();\nConsole.WriteLine(responseBody);\n"
model_card:
  overview: 'library_name: transformers license_link: https://huggingface.co/Qwen/Qwen3-32B/blob/main/LICENSE
    pipeline_tag: text-generation'
  intended_use:
  - Text-Generation tasks
  limitations:
  - May generate biased or harmful content
  - Not suitable for safety-critical applications
  - Performance may vary across different tasks and domains
  training_data: Training data information not specified in model card.
  evaluation:
  - Evaluation metrics not specified in model card
  known_issues:
  - May produce biased content
  - Limited reasoning capabilities
  - Performance varies across languages and domains
  references:
  - https://arxiv.org/abs/2505.09388},
  - https://huggingface.co/Qwen/Qwen3-32B
