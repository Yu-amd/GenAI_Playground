# Blueprint Catalog Template
# This template defines the structure for a single YAML file that contains all blueprints
# in the Inference Hub catalog. Each blueprint is defined as an entry in the blueprints array.

catalog_metadata:
  version: "1.0.0"
  last_updated: "2024-12-19"
  total_blueprints: 0
  categories:
    - Conversational AI
    - Computer Vision
    - Multimodal
    - Code Generation
    - Document Processing
    - Audio Processing
    - Recommendation Systems
    - Search & Retrieval

blueprints:
  # Template for a single blueprint entry
  - blueprint_id: <unique-blueprint-id>  # e.g., chatqna, imagegen, docsummarizer
    name: <Blueprint Display Name>  # e.g., ChatQnA, Image Generator, Document Summarizer
    category: <Category>  # e.g., Conversational AI, Computer Vision, Document Processing
    complexity: <Complexity Level>  # e.g., Beginner, Intermediate, Advanced
    description: >
      Comprehensive description of what the blueprint does, its architecture,
      and key capabilities. This should be detailed enough for users to understand
      the blueprint's purpose and functionality.
    shortDescription: >
      Brief one-line description that appears in catalog listings and cards.
      Should be concise but informative.
    logo: <logo-filename>  # e.g., bp_chatqna.png, bp_imagegen.png
    readiness_level: <Readiness>  # e.g., Production-Ready, Tech Preview, Day-0 Available
    status_badges:
      - <Badge1>  # e.g., Featured, New, Production-Ready, RAG
      - <Badge2>  # e.g., Popular, Trending, Beta
    tags:
      - <Tag1>  # e.g., RAG, Chatbot, Knowledge Base
      - <Tag2>  # e.g., Vector Search, Document Processing
      - <Tag3>  # e.g., Multimodal, API
    status: <Status>  # e.g., Production Ready, Beta, Alpha
    endpoint: <https://api.inference-hub.com/v1/blueprints/<blueprint-id>>
    
    demo_assets:
      notebook: <https://github.com/inference-hub/blueprints/<blueprint-id>-demo.ipynb>
      demo_link: <https://playground.inference-hub.com/blueprints/<blueprint-id>>
    
    aim_recipes:
      - name: <Hardware> <Precision>  # e.g., MI300X FP16, MI250 FP16
        hardware: <Hardware>  # e.g., MI300X, MI250, MI100
        precision: <Precision>  # e.g., fp16, fp8, int8
        recipe_file: configs/<blueprint-id>-<hardware>-<precision>.yaml
    
    blueprint_card:
      overview: >
        Detailed overview of the blueprint, its architecture, and how it works.
        This should provide users with a comprehensive understanding of the
        blueprint's capabilities and implementation approach.
      intended_use:
        - <Use case 1>  # e.g., Customer support chatbots
        - <Use case 2>  # e.g., Knowledge base querying
        - <Use case 3>  # e.g., Document-based Q&A systems
      limitations:
        - <Limitation 1>  # e.g., Requires well-structured knowledge base
        - <Limitation 2>  # e.g., Response quality depends on retrieval accuracy
        - <Limitation 3>  # e.g., May not handle complex multi-step reasoning
      architecture: >
        Brief description of the blueprint's architecture, including key
        components and how they interact.
      evaluation:
        - <Metric 1>: <Value>  # e.g., Response accuracy: 92%
        - <Metric 2>: <Value>  # e.g., Retrieval precision: 89%
        - <Metric 3>: <Value>  # e.g., User satisfaction: 4.2/5
        - <Metric 4>: <Value>  # e.g., Response time: <2 seconds
      known_issues:
        - <Issue 1>  # e.g., Occasional hallucination when knowledge base is incomplete
        - <Issue 2>  # e.g., Performance degradation with very large knowledge bases
        - <Issue 3>  # e.g., Limited context window for complex queries
      references:
        - <Reference URL 1>  # e.g., https://arxiv.org/abs/2005.11401
        - <Reference URL 2>  # e.g., https://github.com/inference-hub/blueprints/<blueprint_id>
    
    microservices:
      models:
        - name: Qwen3 32B
          logo: /src/assets/models/model_Qwen2-7B.png
          tags:
            - Text Generation
            - RAG
            - Inference
            - Reasoning
            - Code Generation
            - Multilingual
      functional:
        - name: Retriever
          description: Vector-based document retrieval service
          tags:
            - RAG
            - Vector Search
            - Document Processing
        - name: Reranking
          description: Re-ranks retrieved documents for better relevance
          tags:
            - RAG
            - Document Ranking
            - Relevance

  # Example blueprint entry (ChatQnA)
  - blueprint_id: chatqna
    name: ChatQnA
    category: Conversational AI
    complexity: Intermediate
    description: Chatbot application based on Retrieval Augmented Generation architecture.
    shortDescription: RAG-based chatbot for knowledge base interactions with advanced retrieval capabilities.
    logo: bp_chatqna.png
    readiness_level: Production-Ready
    status_badges:
      - Featured
      - Production-Ready
      - RAG
    tags:
      - RAG
      - Chatbot
      - Knowledge Base
      - Vector Search
      - Document Processing
    status: Production Ready
    endpoint: https://api.inference-hub.com/v1/blueprints/chatqna
    demo_assets:
      notebook: https://github.com/inference-hub/blueprints/chatqna-demo.ipynb
      demo_link: https://playground.inference-hub.com/blueprints/chatqna
    aim_recipes:
      - name: MI300X FP16
        hardware: MI300X
        precision: fp16
        recipe_file: configs/chatqna-mi300x-fp16.yaml
      - name: MI250 FP16
        hardware: MI250
        precision: fp16
        recipe_file: configs/chatqna-mi250-fp16.yaml
    blueprint_card:
      overview: ChatQnA is a Retrieval Augmented Generation (RAG) based chatbot that combines large language models with external knowledge bases to provide accurate, context-aware responses.
      intended_use:
        - Customer support chatbots
        - Knowledge base querying
        - Document-based Q&A systems
        - Technical support automation
      limitations:
        - Requires well-structured knowledge base
        - Response quality depends on retrieval accuracy
        - May not handle complex multi-step reasoning
        - Limited to information in the knowledge base
      architecture: RAG pipeline with vector database, embedding model, and LLM for generation
      evaluation:
        - "Response accuracy: 92%"
        - "Retrieval precision: 89%"
        - "User satisfaction: 4.2/5"
        - "Response time: <2 seconds"
      known_issues:
        - Occasional hallucination when knowledge base is incomplete
        - Performance degradation with very large knowledge bases
        - Limited context window for complex queries
      references:
        - https://arxiv.org/abs/2005.11401
        - https://github.com/inference-hub/blueprints/chatqna
    microservices:
      models:
        - name: Qwen3 32B
          logo: /src/assets/models/model_Qwen2-7B.png
          tags:
            - Text Generation
            - RAG
            - Inference
            - Reasoning
            - Code Generation
            - Multilingual
      functional:
        - name: Retriever
          description: Vector-based document retrieval service
          tags:
            - RAG
            - Vector Search
            - Document Processing
        - name: Reranking
          description: Re-ranks retrieved documents for better relevance
          tags:
            - RAG
            - Document Ranking
            - Relevance

  # Add more blueprint entries here following the same structure
  # - blueprint_id: imagegen
  #   name: Image Generator
  #   category: Computer Vision
  #   ...

# Usage Instructions:
# 1. Replace all placeholder values (enclosed in <>) with actual data
# 2. Add new blueprint entries by copying the template structure
# 3. Update catalog_metadata.total_blueprints count
# 4. Ensure all blueprint_ids are unique
# 5. Validate YAML syntax before committing
# 6. Update the blueprint loader to read from this catalog file 