model_id: google/gemma-3-4b-it
name: Gemma 3 4B IT
builder: Google DeepMind
family: Gemma
size: 4B
huggingface_id: google/gemma-3-4b-it

description: >
  Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants.

logo: model_Gemma.png

readiness_level: Production-Ready
status_badges:
  - FP16
  - FlashAttention
  - Featured

tags:
  - Multimodal
  - Lightweight
  - Open Weights
  - Instruction-Tuned
  - vLLM-Compatible
  - sglang-Compatible

license: Apache 2.0

endpoint: https://api.inference-hub.com/v1/chat/completions

demo_assets:
  notebook: https://github.com/inference-hub/notebooks/gemma-3-4b-it-demo.ipynb
  demo_link: https://playground.inference-hub.com/models/google/gemma-3-4b-it

aim_recipes:
  - name: MI300X FP16
    hardware: MI300X
    precision: fp16
    recipe_file: configs/gemma-3-4b-it-mi300x-fp16.yaml

  - name: MI250 FP16
    hardware: MI250
    precision: fp16
    recipe_file: configs/gemma-3-4b-it-mi250-fp16.yaml

api_examples:
  python: |
    import requests

    headers = {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "google/gemma-3-4b-it",
        "messages": [{"role": "user", "content": "Hello"}],
        "stream": False
    }

    response = requests.post("https://api.inference-hub.com/v1/chat/completions", headers=headers, json=payload)
    print(response.json())

  javascript: |
    const response = await fetch("https://api.inference-hub.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "google/gemma-3-4b-it",
        messages: [{ role: "user", content: "Hello" }],
        stream: false
      })
    });

    const data = await response.json();
    console.log(data.choices[0].message.content);

  shell: |
    curl -X POST https://api.inference-hub.com/v1/chat/completions \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "google/gemma-3-4b-it",
        "messages": [{"role": "user", "content": "Hello"}],
        "stream": false
      }'

  java: |
    HttpClient client = HttpClient.newHttpClient();
    HttpRequest request = HttpRequest.newBuilder()
        .uri(URI.create("https://api.inference-hub.com/v1/chat/completions"))
        .header("Authorization", "Bearer YOUR_API_KEY")
        .header("Content-Type", "application/json")
        .POST(HttpRequest.BodyPublishers.ofString("""
          {
            "model": "google/gemma-3-4b-it",
            "messages": [{"role": "user", "content": "Hello"}],
            "stream": false
          }
        """))
        .build();

    HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());
    System.out.println(response.body());

  go: |
    package main

    import (
        "bytes"
        "fmt"
        "io/ioutil"
        "net/http"
    )

    func main() {
        jsonStr := []byte(`{
            "model": "google/gemma-3-4b-it",
            "messages": [{"role": "user", "content": "Hello"}],
            "stream": false
        }`)

        req, _ := http.NewRequest("POST", "https://api.inference-hub.com/v1/chat/completions", bytes.NewBuffer(jsonStr))
        req.Header.Set("Authorization", "Bearer YOUR_API_KEY")
        req.Header.Set("Content-Type", "application/json")

        client := &http.Client{}
        resp, _ := client.Do(req)
        body, _ := ioutil.ReadAll(resp.Body)
        fmt.Println(string(body))
    }

  csharp: |
    using System.Net.Http;
    using System.Text;
    using System.Threading.Tasks;

    var client = new HttpClient();
    var request = new HttpRequestMessage(HttpMethod.Post, "https://api.inference-hub.com/v1/chat/completions");
    request.Headers.Add("Authorization", "Bearer YOUR_API_KEY");

    var json = """
    {
        "model": "google/gemma-3-4b-it",
        "messages": [{"role": "user", "content": "Hello"}],
        "stream": false
    }
    """;

    request.Content = new StringContent(json, Encoding.UTF8, "application/json");

    var response = await client.SendAsync(request);
    var responseBody = await response.Content.ReadAsStringAsync();
    Console.WriteLine(responseBody);

model_card:
  overview: >
    Gemma 3 4B IT is a lightweight, multimodal instruction-tuned model from Google DeepMind. 
    Built using the same research and technology as the Gemini models, it handles both text 
    and image inputs while generating text output. The model offers excellent performance 
    for its size and is designed for efficient deployment.

  intended_use:
    - Multimodal conversations
    - Image understanding and analysis
    - Text generation and completion
    - Conversational AI
    - Document understanding with images
    - Lightweight deployment scenarios

  limitations:
    - May hallucinate facts
    - Not suitable for safety-critical use
    - Limited context window compared to larger models
    - Performance may vary on complex multimodal tasks
    - Image understanding capabilities are limited compared to larger models

  training_data: >
    Multimodal dataset including text and images from web sources, filtered for quality and safety.
    Training data cutoff: February 2024.

  evaluation:
    - "MMLU: 66.8"
    - "HumanEval (code): 38.2%"
    - "MT-Bench: 7.9"
    - "GSM8K: 76.3%"
    - "VQA: 78.5%"

  known_issues:
    - May produce biased content
    - Image understanding can be inconsistent
    - Performance varies across different image types
    - Limited reasoning capabilities compared to larger models

  references:
    - https://huggingface.co/google/gemma-3-4b-it
    - https://github.com/google/gemma
    - https://ai.google.dev/gemma 