blueprint_id: chatqna
name: ChatQnA
category: Conversational AI
complexity: Intermediate
description: Chatbot application based on Retrieval Augmented Generation architecture.
shortDescription: RAG-based chatbot for knowledge base interactions with advanced retrieval capabilities.
logo: bp_chatqna.png
readiness_level: Production-Ready
status_badges:
  - Featured
  - Production-Ready
  - RAG
tags:
  - RAG
  - Chatbot
  - Knowledge Base
  - Vector Search
  - Document Processing
status: Production Ready
endpoint: https://api.inference-hub.com/v1/blueprints/chatqna
demo_assets:
  notebook: https://github.com/inference-hub/blueprints/chatqna-demo.ipynb
  demo_link: https://playground.inference-hub.com/blueprints/chatqna
aim_recipes:
  - name: MI300X FP16
    hardware: MI300X
    precision: fp16
    recipe_file: configs/chatqna-mi300x-fp16.yaml
  - name: MI250 FP16
    hardware: MI250
    precision: fp16
    recipe_file: configs/chatqna-mi250-fp16.yaml
api_examples:
  python: |
    import requests

    headers = {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    }

    payload = {
        "blueprint": "chatqna",
        "query": "What is the OPEA Framework?",
        "knowledge_base": "opea_docs",
        "stream": False
    }

    response = requests.post("https://api.inference-hub.com/v1/blueprints/chatqna", headers=headers, json=payload)
    print(response.json())
  typescript: |
    const response = await fetch("https://api.inference-hub.com/v1/blueprints/chatqna", {
      method: "POST",
      headers: {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        blueprint: "chatqna",
        query: "What is the OPEA Framework?",
        knowledge_base: "opea_docs",
        stream: false
      })
    });

    const data = await response.json();
    console.log(data.response);
  shell: |
    curl -X POST https://api.inference-hub.com/v1/blueprints/chatqna \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "blueprint": "chatqna",
        "query": "What is the OPEA Framework?",
        "knowledge_base": "opea_docs",
        "stream": false
      }'
  rust: |
    use axum::{
        extract::Json,
        http::StatusCode,
        response::sse::{Event, Sse},
        routing::post,
        Router,
    };
    use serde::{Deserialize, Serialize};
    use std::convert::Infallible;
    use tokio_stream::wrappers::ReceiverStream;

    #[derive(Deserialize)]
    struct ChatQnARequest {
        blueprint: String,
        query: String,
        knowledge_base: String,
        stream: bool,
    }

    async fn chatqna_completion(Json(payload): Json<ChatQnARequest>) -> Sse<impl Stream<Item = Result<Event, Infallible>>> {
        let (tx, rx) = tokio::sync::mpsc::channel(100);
        
        tokio::spawn(async move {
            // Simulate RAG response
            let response = format!("RAG response for query: {}", payload.query);
            for chunk in response.chars() {
                let event = Event::default().data(chunk.to_string());
                let _ = tx.send(Ok(event)).await;
                tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
            }
        });
        
        Sse::new(ReceiverStream::new(rx))
    }

    #[tokio::main]
    async fn main() {
        let app = Router::new()
            .route("/blueprints/chatqna", post(chatqna_completion));
        
        axum::Server::bind(&"0.0.0.0:3000".parse().unwrap())
            .serve(app.into_make_service())
            .await
            .unwrap();
    }
  go: |
    package main

    import (
        "bytes"
        "fmt"
        "io/ioutil"
        "net/http"
    )

    func main() {
        jsonStr := []byte(`{
            "blueprint": "chatqna",
            "query": "What is the OPEA Framework?",
            "knowledge_base": "opea_docs",
            "stream": false
        }`)

        req, _ := http.NewRequest("POST", "https://api.inference-hub.com/v1/blueprints/chatqna", bytes.NewBuffer(jsonStr))
        req.Header.Set("Authorization", "Bearer YOUR_API_KEY")
        req.Header.Set("Content-Type", "application/json")

        client := &http.Client{}
        resp, _ := client.Do(req)
        body, _ := ioutil.ReadAll(resp.Body)
        fmt.Println(string(body))
    }
blueprint_card:
  overview: ChatQnA is a Retrieval Augmented Generation (RAG) based chatbot that combines large language models with external knowledge bases to provide accurate, context-aware responses.
  intended_use:
    - Customer support chatbots
    - Knowledge base querying
    - Document-based Q&A systems
    - Technical support automation
  limitations:
    - Requires well-structured knowledge base
    - Response quality depends on retrieval accuracy
    - May not handle complex multi-step reasoning
    - Limited to information in the knowledge base
  architecture: RAG pipeline with vector database, embedding model, and LLM for generation
  evaluation:
    - Response accuracy: 92%
    - Retrieval precision: 89%
    - User satisfaction: 4.2/5
    - Response time: <2 seconds
  known_issues:
    - Occasional hallucination when knowledge base is incomplete
    - Performance degradation with very large knowledge bases
    - Limited context window for complex queries
  references:
    - https://arxiv.org/abs/2005.11401
    - https://github.com/inference-hub/blueprints/chatqna
microservices:
  models:
    - name: Qwen2 7B
      logo: /src/assets/models/model_Qwen2-7B.png
      tags:
        - Text Generation
        - RAG
        - Inference
    - name: Embedding Model
      logo: /src/assets/models/model_embedding.png
      tags:
        - Embeddings
        - Vector Search
  functional:
    - name: Retriever
      description: Vector-based document retrieval service
      tags:
        - RAG
        - Vector Search
        - Document Processing
    - name: Reranking
      description: Re-ranks retrieved documents for better relevance
      tags:
        - RAG
        - Document Ranking
        - Relevance 